import os
import json
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI

from langchain_core.output_parsers import StructuredOutputParser, ResponseSchema, RetryWithErrorFixingParser
from langchain_core.prompts import PromptTemplate
from langchain import LLMChain
from utils.prompts.prompt import prompt_text

# ìŠ¤íŒ¸ë©”ì¼ ì²˜ë¦¬ ë¡œì§ í”¼ë“œë°±.
# ì •í™•ë„ë¡œ í•˜ë ¤ë©´ ìˆëŠ” íƒœê·¸ë“¤ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ì„œ ì§‘ì–´ë„£ì–´ë‹¬ë¼ê³  ì§€ì‹œë¥¼ ì£¼ë©´ ê·¸ê²Œ ì¢‹ì„ ê²ƒ ê°™ë‹¤.
# ê°œë³„ ë©”ì¼ ë‹¨ìœ„ë¡œ iterationí•˜ê³  ê²€ì¦ìš© ìš”ì²­ë„ í•˜ë‚˜ ë³´ë‚´ë†“ëŠ” ê±° ì¢‹ì•„ë³´ì„.

response_schemas = [
    ResponseSchema(
        name="classification",
        description='A JSON object mapping each email "id" (string) to "spam" or "inbox". Example: {"101": "inbox", "102": "spam"}',
    )
]

structured_parser = StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions = structured_parser.get_format_instructions()


def classify_emails_in_batch(emails: list, job: str, interests: list, usage: str) -> dict:
    """
    ì—¬ëŸ¬ ì´ë©”ì¼ê³¼ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ LLMì— í•œ ë²ˆì— ë³´ë‚´ì–´ ìŠ¤íŒ¸ ì—¬ë¶€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

    Args:
        emails (list): ê° ìš”ì†Œê°€ {'id': str, 'subject': str, 'body': str} í˜•íƒœì¸ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        job (str): ì‚¬ìš©ìì˜ ì§ì—…
        interests (list): ì‚¬ìš©ìì˜ ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        usage (str): ê³„ì •ì˜ ìš©ë„

    Returns:
        dict: ì´ë©”ì¼ IDë¥¼ í‚¤ë¡œ, 'spam' ë˜ëŠ” 'inbox'ë¥¼ ê°’ìœ¼ë¡œ ê°–ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    load_dotenv()
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        print("Error: GOOGLE_API_KEY not found in .env file")
        return {}

    spam_filter_prompt = PromptTemplate.from_template(prompt_text)

    # LLM ì´ˆê¸°í™”
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-pro",
            temperature=0,
            google_api_key=api_key,
        )

        # JSON í˜•ì‹ ì˜¤ë¥˜ ìë™ ìˆ˜ì • íŒŒì„œ
        retry_parser = RetryWithErrorFixingParser.from_llm(
            parser=structured_parser,
            llm=llm,
        )

        chain = LLMChain(
            llm=llm,
            prompt=spam_filter_prompt,
            output_parser=retry_parser,  # ğŸš€ ìë™ ë³µêµ¬ íŒŒì„œ ì—°ê²°
            output_key="classification",
        )

        # LLM í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œí‚¤ê¸° ìœ„í•´ ì´ë©”ì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        emails_json_string = json.dumps(emails, indent=2, ensure_ascii=False)

        result = chain.invoke(
            {
                "job": job,
                "interests": ", ".join(interests),
                "usage": usage,
                "emails": emails_json_string,
            }
        )

        # ê²°ê³¼ì—ì„œ ë¶„ë¥˜ ê²°ê³¼ ì¶”ì¶œ
        classification_results = result.get("classification", {})
        return classification_results
    except Exception as e:
        print(f"Error during email classification: {e}")
        return {}
